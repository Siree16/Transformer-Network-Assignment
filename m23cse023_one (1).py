# -*- coding: utf-8 -*-
"""M23CSE023_one

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xeANWahJevL2UsmHbKB2Ss1RSN2rQKr9
"""

!pip install wandb lightning

from google.colab import drive
drive.mount('/content/drive')

# Importing Libraries
print('Importing Libraries... ',end='')
import os
from pathlib import Path
import pandas as pd
import torchaudio
import zipfile
from torchaudio.transforms import Resample
import IPython.display as ipd
from matplotlib import pyplot as plt
from tqdm import tqdm
import pytorch_lightning as pl
from torch.utils.data import Dataset, DataLoader
import torch
from pytorch_lightning.loggers import WandbLogger

# Loading dataset
path = Path('/content/drive/MyDrive/Archive/audio')
df = pd.read_csv('/content/drive/MyDrive/Archive/meta/esc50.csv')

df.head()

df['category'].value_counts()

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from pathlib import Path
import torchaudio
from torchvision.transforms import Compose
import torchaudio.transforms as T
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc
from sklearn.model_selection import StratifiedKFold
import pandas as pd
from sklearn.preprocessing import LabelEncoder
import wandb


def preprocess_audio(batch, sample_rate=44100):
    waveforms = []
    targets = []

    for audio_file, target in batch:
        waveform, _ = torchaudio.load(audio_file, normalize=True)

        transform = Compose([
            T.Resample(orig_freq=sample_rate, new_freq=16000),
            T.MFCC(),
            T.TimeMasking(time_mask_param=20),
            T.FrequencyMasking(freq_mask_param=30)
        ])

        processed_waveform = transform(waveform)
        waveforms.append(processed_waveform)
        targets.append(target)

    return torch.stack(waveforms).squeeze(1), torch.tensor(targets)


class CustomConvNet(nn.Module):
    def __init__(self, num_classes, num_channels=40):
        super(CustomConvNet, self).__init__()
        self.model = nn.Sequential(
            nn.Conv1d(num_channels, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.MaxPool1d(kernel_size=2, stride=2),

            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.MaxPool1d(kernel_size=2, stride=2),

            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.MaxPool1d(kernel_size=2, stride=2),

            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.model(x)


def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):
    best_val_loss = float('inf')
    patience = 5
    epochs_no_improve = 0

    wandb.watch(model, log='all')

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct_predictions = 0
        total_samples = 0

        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            correct_predictions += (predicted == targets).sum().item()
            total_samples += targets.size(0)

        train_loss = running_loss / len(train_loader)
        train_accuracy = correct_predictions / total_samples

        # Validation
        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion, device)

        wandb.log({'epoch': epoch + 1, 'train_loss': train_loss, 'train_accuracy': train_accuracy,
                   'val_loss': val_loss, 'val_accuracy': val_accuracy})

        print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, "
              f"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}")


        # if val_loss < best_val_loss:
        #     best_val_loss = val_loss
        #     epochs_no_improve = 0
        # else:
        #     epochs_no_improve += 1
        #     if epochs_no_improve == patience:
        #         print("Early stopping!")
        #         break

    print("Training completed.")


def evaluate_model(model, test_loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct_predictions = 0
    total_samples = 0

    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            running_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            correct_predictions += (predicted == targets).sum().item()
            total_samples += targets.size(0)

    loss = running_loss / len(test_loader)
    accuracy = correct_predictions / total_samples

    return loss, accuracy


def count_parameters(model):
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    non_trainable_params = total_params - trainable_params
    return total_params, trainable_params, non_trainable_params


path = '/content/drive/MyDrive/Archive/audio'
df = pd.read_csv('/content/drive/MyDrive/Archive/meta/esc50.csv')


esc_10_flag = True
if esc_10_flag:
    df = df[df['esc10'] == True]


wandb.init(project='Archi1_K_fold', name='missclassyfyed', config={'epochs': 100, 'learning_rate': 0.001})


kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)
fold = 1


best_accuracy = 0.0
best_hyperparameters = {}


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


label_encoder = LabelEncoder()
df['target'] = label_encoder.fit_transform(df['category'])
num_classes = len(label_encoder.classes_)

# for num_epochs in [5]:
#     for learning_rate in [0.001,0.01,0.1]:
#         for batch_size in [32,64,128]:

for num_epochs in [100]:
    for learning_rate in [0.001]:
        for batch_size in [32,64]:
            all_accuracies = []
            all_auc_roc_scores = []
            all_confusion_matrices = []
            all_f1_scores=[]



            for train_indices, test_indices in kfold.split(df[['filename', 'target']], df['target']):
                train_data, test_data = df.iloc[train_indices], df.iloc[test_indices]

                model = CustomConvNet(num_classes=num_classes, num_channels=40)
                model.to(device)

                criterion = nn.CrossEntropyLoss()
                optimizer = optim.Adam(model.parameters(), lr=learning_rate)

                train_dataset = [(Path(path) / filename, target) for filename, target in
                                 zip(train_data['filename'], train_data['target'])]
                test_dataset = [(Path(path) / filename, target) for filename, target in
                                zip(test_data['filename'], test_data['target'])]

                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,
                                          collate_fn=preprocess_audio)
                test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,
                                         collate_fn=preprocess_audio)


                val_size = int(0.1 * len(train_loader.dataset))
                train_size = len(train_loader.dataset) - val_size
                train_dataset, val_dataset = torch.utils.data.random_split(train_loader.dataset, [train_size, val_size])

                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,
                                          collate_fn=preprocess_audio)
                val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,
                                        collate_fn=preprocess_audio)


                train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)


                test_loss, test_accuracy = evaluate_model(model, test_loader, criterion, device)
                print(f"Fold {fold}, Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")


                all_accuracies.append(test_accuracy)


                y_true, y_pred = [], []
                with torch.no_grad():
                    for inputs, targets in test_loader:
                        inputs, targets = inputs.to(device), targets.to(device)
                        outputs = model(inputs)
                        _, predicted = torch.max(outputs, 1)
                        y_true.extend(targets.cpu().numpy())
                        y_pred.extend(predicted.cpu().numpy())

                confusion_matrix_fold = confusion_matrix(y_true, y_pred)
                all_confusion_matrices.append(confusion_matrix_fold)


                f1_scores_fold = classification_report(y_true, y_pred, output_dict=True)['macro avg']['f1-score']
                all_f1_scores.append(f1_scores_fold)


                all_y_true = []
                all_y_probs = []

                with torch.no_grad():
                    for inputs, targets in test_loader:
                        inputs, targets = inputs.to(device), targets.to(device)
                        outputs = model(inputs)
                        _, predicted = torch.max(outputs, 1)

                        all_y_true.extend(targets.cpu().numpy())
                        all_y_probs.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())


                auc_roc_score_fold = roc_auc_score(all_y_true, all_y_probs, multi_class='ovr')
                all_auc_roc_scores.append(auc_roc_score_fold)

                fold += 1


            average_accuracy = sum(all_accuracies) / len(all_accuracies)
            average_auc_roc_score = sum(all_auc_roc_scores) / len(all_auc_roc_scores)

            average_confusion_matrix = sum(all_confusion_matrices) / len(all_confusion_matrices)
            average_f1_score=sum(all_f1_scores)/len(all_f1_scores)


            print(f"\nHyperparameters: {num_epochs} epochs, {learning_rate} learning rate, {batch_size} batch size")
            print(f"Average Accuracy: {average_accuracy}")
            print("Average Confusion Matrix:\n", average_confusion_matrix)
            print(f"Average F1 Score: {average_f1_score}")
            print(f"Average AUC-ROC Score: {average_auc_roc_score}")


            if average_accuracy > best_accuracy:
                best_accuracy = average_accuracy
                best_hyperparameters = {'num_epochs': num_epochs, 'learning_rate': learning_rate,
                                        'batch_size': batch_size}


model = CustomConvNet(num_classes=num_classes, num_channels=40)
total_params, trainable_params, non_trainable_params = count_parameters(model)
print(f"\nTotal Trainable Parameters: {trainable_params}")
print(f"Total Non-trainable Parameters: {non_trainable_params}")

print("\nBest Hyperparameters:", best_hyperparameters)

wandb.finish()





import torch
import torch.nn as nn
import torch.optim as optim
import wandb
from torch.utils.data import DataLoader
import pandas as pd
from pathlib import Path
import torchaudio
from torchvision.transforms import Compose
import torchaudio.transforms as T
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.preprocessing import LabelEncoder
import seaborn as sns



def preprocess_audio(batch, sample_rate=44100):
    waveforms = []
    targets = []

    for audio_file, target in batch:
        waveform, _ = torchaudio.load(audio_file, normalize=True)

        transform = Compose([
            T.Resample(orig_freq=sample_rate, new_freq=16000),
            T.MFCC(),
        ])

        processed_waveform = transform(waveform)
        waveforms.append(processed_waveform)
        targets.append(target)

    return torch.stack(waveforms).squeeze(1), torch.tensor(targets)



class CustomConvNet(nn.Module):
    def __init__(self, num_classes, num_channels=40):
        super(CustomConvNet, self).__init__()
        self.model = nn.Sequential(
            nn.Conv1d(num_channels, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Dropout(0.25),

            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Dropout(0.25),

            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Dropout(0.25),

            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.model(x)



def train_model(model, train_loader, criterion, optimizer, num_epochs, device):
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct_predictions = 0
        total_samples = 0

        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            correct_predictions += (predicted == targets).sum().item()
            total_samples += targets.size(0)

        accuracy = correct_predictions / total_samples

        wandb.log({'epoch': epoch + 1, 'loss': running_loss / len(train_loader), 'accuracy': accuracy})
        print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Accuracy: {accuracy:.4f}")



def evaluate_model(model, test_loader, device):
    model.eval()
    all_predictions = []
    all_targets = []
    all_probs = []
    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())

            probs = nn.functional.softmax(outputs, dim=1)
            all_probs.extend(probs.cpu().numpy())
    return all_predictions, all_targets, np.array(all_probs)


def count_parameters(model):
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    non_trainable_params = total_params - trainable_params
    return total_params, trainable_params, non_trainable_params



num_epochs =100
learning_rate = 0.1
batch_sizes = [32, 64]


path = '/content/drive/MyDrive/Archive/audio'
df = pd.read_csv('/content/drive/MyDrive/Archive/meta/esc50.csv')


esc_10_flag = True
if esc_10_flag:
    df = df[df['esc10'] == True]


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


label_encoder = LabelEncoder()
df['target'] = label_encoder.fit_transform(df['category'])
num_classes = len(label_encoder.classes_)


train_data, test_data = train_test_split(df, test_size=0.2, stratify=df['target'], random_state=42)


wandb.init(project='Archi1_tt_final', name='m23cse023', config={'epochs': num_epochs, 'learning_rate': learning_rate})

for batch_size in batch_sizes:
    wandb.config.batch_size = batch_size


    model = CustomConvNet(num_classes=num_classes, num_channels=40)
    model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)


    train_dataset = [(Path(path) / filename, target) for filename, target in zip(train_data['filename'], train_data['target'])]
    test_dataset = [(Path(path) / filename, target) for filename, target in zip(test_data['filename'], test_data['target'])]
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=preprocess_audio)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=preprocess_audio)


    train_model(model, train_loader, criterion, optimizer, num_epochs, device)


    total_params, trainable_params, non_trainable_params = count_parameters(model)
    print(f"Total Parameters: {total_params}, Trainable Parameters: {trainable_params}, Non-trainable Parameters: {non_trainable_params}")


    model.eval()
    all_predictions, all_targets, all_probs = evaluate_model(model, test_loader, device)


    test_accuracy = accuracy_score(all_targets, all_predictions)
    print(f"Test Accuracy for batch size {batch_size}: {test_accuracy}")


    cm = confusion_matrix(all_targets, all_predictions)
    print(f"Confusion Matrix for batch size {batch_size}:\n{cm}")
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
    plt.title(f'Confusion Matrix for batch size {batch_size}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()


    report = classification_report(all_targets, all_predictions)
    print(f"Classification Report for batch size {batch_size}:\n{report}")


    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(num_classes):
        fpr[i], tpr[i], _ = roc_curve((np.array(all_targets) == i).astype(int), all_probs[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    plt.figure()
    for i in range(num_classes):
        plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {i}')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC curves for each class (batch size {batch_size})')
    plt.legend(loc="lower right")
    plt.show()


wandb.finish()



#orignal without logging

import torch
import torch.nn as nn
import torch.optim as optim
import wandb
from torch.utils.data import DataLoader
import pandas as pd
from pathlib import Path
import torchaudio
from torchvision.transforms import Compose
import torchaudio.transforms as T
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.preprocessing import LabelEncoder


def preprocess_audio(batch, sample_rate=44100):
    waveforms = []
    targets = []

    for audio_file, target in batch:
        waveform, _ = torchaudio.load(audio_file, normalize=True)

        transform = Compose([
            T.Resample(orig_freq=sample_rate, new_freq=16000),
            T.MFCC(),
        ])

        processed_waveform = transform(waveform)
        waveforms.append(processed_waveform)
        targets.append(target)

    return torch.stack(waveforms).squeeze(1), torch.tensor(targets)


class CustomConvNet(nn.Module):
    def __init__(self, num_classes, num_channels=40):
        super(CustomConvNet, self).__init__()
        self.model = nn.Sequential(
            nn.Conv1d(num_channels, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Dropout(0.25),

            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Dropout(0.25),

            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Dropout(0.25),

            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(128, num_classes)  #
        )

    def forward(self, x):
        return self.model(x)


def train_model(model, train_loader, criterion, optimizer, num_epochs, device):
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct_predictions = 0
        total_samples = 0

        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            correct_predictions += (predicted == targets).sum().item()
            total_samples += targets.size(0)

        accuracy = correct_predictions / total_samples

        wandb.log({'epoch': epoch + 1, 'loss': running_loss / len(train_loader), 'accuracy': accuracy})
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}")


def evaluate_model(model, test_loader, device):
    model.eval()
    all_predictions = []
    all_targets = []
    all_probs = []
    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())

            probs = nn.functional.softmax(outputs, dim=1)
            all_probs.extend(probs.cpu().numpy())
    return all_predictions, all_targets, np.array(all_probs)


def count_parameters(model):
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    non_trainable_params = total_params - trainable_params
    return total_params, trainable_params, non_trainable_params


num_epochs = 100
learning_rate = 0.001
batch_sizes = [32, 64]


path = '/content/drive/MyDrive/Archive/audio'
df = pd.read_csv('/content/drive/MyDrive/Archive/meta/esc50.csv')


esc_10_flag = True
if esc_10_flag:
    df = df[df['esc10'] == True]




best_accuracy = 0.0
best_hyperparameters = {}


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


label_encoder = LabelEncoder()
df['target'] = label_encoder.fit_transform(df['category'])
num_classes = len(label_encoder.classes_)


train_data, test_data = train_test_split(df, test_size=0.2, stratify=df['target'], random_state=42)

for batch_size in batch_sizes:

    wandb.init(project='Archi1_tt', name=f'm23cse023_batch_{batch_size}', config={'epochs': num_epochs, 'learning_rate': learning_rate, 'batch_size': batch_size})

    model = CustomConvNet(num_classes=num_classes, num_channels=40)
    model.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    train_dataset = [(Path(path) / filename, target) for filename, target in zip(train_data['filename'], train_data['target'])]
    test_dataset = [(Path(path) / filename, target) for filename, target in zip(test_data['filename'], test_data['target'])]

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=preprocess_audio)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=preprocess_audio)


    train_model(model, train_loader, criterion, optimizer, num_epochs, device)
    total_params, trainable_params, non_trainable_params = count_parameters(model)
    print(f"Total Parameters: {total_params}, Trainable Parameters: {trainable_params}, Non-trainable Parameters: {non_trainable_params}")


    model.eval()
    all_predictions, all_targets, all_probs = evaluate_model(model, test_loader, device)


    test_accuracy = accuracy_score(all_targets, all_predictions)
    print(f"Test Accuracy for batch size {batch_size}: {test_accuracy}")

    cm = confusion_matrix(all_targets, all_predictions)
    print(f"Confusion Matrix for batch size {batch_size}:\n{cm}")

    report = classification_report(all_targets, all_predictions)
    print(f"Classification Report for batch size {batch_size}:\n{report}")


    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(num_classes):
        fpr[i], tpr[i], _ = roc_curve((np.array(all_targets) == i).astype(int), all_probs[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])


    plt.figure()
    for i in range(num_classes):
        plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {i}')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC curves for each class (batch size {batch_size})')
    plt.legend(loc="lower right")
    plt.show()

    wandb.finish()

#optimmized

import torch
import torch.nn as nn
import torch.optim as optim
import wandb
from torch.utils.data import DataLoader
import pandas as pd
from pathlib import Path
import torchaudio
from torchvision.transforms import Compose
import torchaudio.transforms as T
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, auc, roc_curve
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.preprocessing import LabelEncoder



def preprocess_audio(batch, sample_rate=44100):
    waveforms = []
    targets = []

    for audio_file, target in batch:
        waveform, _ = torchaudio.load(audio_file, normalize=True)

        transform = Compose([
            T.Resample(orig_freq=sample_rate, new_freq=16000),
            T.MFCC(),
        ])

        processed_waveform = transform(waveform)
        waveforms.append(processed_waveform)
        targets.append(target)

    return torch.stack(waveforms).squeeze(1), torch.tensor(targets)


class CustomConvNet(nn.Module):
    def __init__(self, num_classes, num_channels=40):
        super(CustomConvNet, self).__init__()
        self.model = nn.Sequential(
            nn.Conv1d(num_channels, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Dropout(0.5),

            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Dropout(0.5),

            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Dropout(0.5),

            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.model(x)


def train_model(model, train_loader, criterion, optimizer, num_epochs, device, early_stopping_patience=10):
    best_validation_loss = float('inf')
    consecutive_no_improvement = 0

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct_predictions = 0
        total_samples = 0

        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            correct_predictions += (predicted == targets).sum().item()
            total_samples += targets.size(0)

        accuracy = correct_predictions / total_samples

        wandb.log({'epoch': epoch + 1, 'loss': running_loss / len(train_loader), 'accuracy': accuracy})
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}")


        model.eval()
        validation_loss = 0.0
        correct_predictions_val = 0
        total_samples_val = 0

        with torch.no_grad():
            for inputs_val, targets_val in validation_loader:
                inputs_val, targets_val = inputs_val.to(device), targets_val.to(device)
                outputs_val = model(inputs_val)
                loss_val = criterion(outputs_val, targets_val)
                validation_loss += loss_val.item()

                _, predicted_val = torch.max(outputs_val, 1)
                correct_predictions_val += (predicted_val == targets_val).sum().item()
                total_samples_val += targets_val.size(0)

        accuracy_val = correct_predictions_val / total_samples_val
        average_loss_val = validation_loss / len(validation_loader)

        print(f"Validation Loss: {average_loss_val:.4f}, Validation Accuracy: {accuracy_val:.4f}")

        # # Check for early stopping
        # if average_loss_val < best_validation_loss:
        #     best_validation_loss = average_loss_val
        #     consecutive_no_improvement = 0
        # else:
        #     consecutive_no_improvement += 1

        # if consecutive_no_improvement >= early_stopping_patience:
        #     print("Early stopping")
        #     break


def evaluate_model(model, test_loader, device):
    model.eval()
    all_predictions = []
    all_targets = []
    all_probs = []

    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())

            probs = nn.functional.softmax(outputs, dim=1)
            all_probs.extend(probs.cpu().numpy())

    return all_predictions, all_targets, np.array(all_probs)


def count_parameters(model):
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    non_trainable_params = total_params - trainable_params
    return total_params, trainable_params, non_trainable_params


torch.manual_seed(42)
np.random.seed(42)


num_epochs = 100
learning_rate = 0.001
batch_sizes = [32, 64]


path = '/content/drive/MyDrive/Archive/audio'


df = pd.read_csv('/content/drive/MyDrive/Archive/meta/esc50.csv')


esc_10_flag = True
if esc_10_flag:
    df = df[df['esc10'] == True]


wandb.init(project='Archi1_tt_opti_ver', name='m23cse023', config={'epochs': num_epochs, 'learning_rate': learning_rate})


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


label_encoder = LabelEncoder()
df['target'] = label_encoder.fit_transform(df['category'])
num_classes = len(label_encoder.classes_)


train_data, test_data = train_test_split(df, test_size=0.2, stratify=df['target'], random_state=42)


best_accuracy = 0.0
best_hyperparameters = {}


for batch_size in batch_sizes:
    wandb.init(project='Archi1_tt', name=f'm23cse023_batch_{batch_size}', config={'epochs': num_epochs, 'learning_rate': learning_rate, 'batch_size': batch_size})


    model = CustomConvNet(num_classes=num_classes, num_channels=40).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)


    train_dataset = [(Path(path) / filename, target) for filename, target in zip(train_data['filename'], train_data['target'])]
    test_dataset = [(Path(path) / filename, target) for filename, target in zip(test_data['filename'], test_data['target'])]

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=preprocess_audio)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=preprocess_audio)


    train_size = int(0.8 * len(train_loader.dataset))
    validation_size = len(train_loader.dataset) - train_size
    train_dataset, validation_dataset = torch.utils.data.random_split(train_loader.dataset, [train_size, validation_size])

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=preprocess_audio)
    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=preprocess_audio)

    total_params, trainable_params, non_trainable_params = count_parameters(model)
    print(f"Total Parameters: {total_params}, Trainable Parameters: {trainable_params}, Non-trainable Parameters: {non_trainable_params}")

    # # Set up early stopping
    # early_stopping_patience = 10
    # early_stopping = EarlyStopping(patience=early_stopping_patience, verbose=True)


    train_model(model, train_loader, criterion, optimizer, num_epochs, device)


    all_predictions, all_targets, all_probs = evaluate_model(model, test_loader, device)
    test_accuracy = accuracy_score(all_targets, all_predictions)
    print(f"Test Accuracy for batch size {batch_size}: {test_accuracy}")

    cm = confusion_matrix(all_targets, all_predictions)
    print(f"Confusion Matrix for batch size {batch_size}:\n{cm}")

    report = classification_report(all_targets, all_predictions)
    print(f"Classification Report for batch size {batch_size}:\n{report}")


    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(num_classes):
        fpr[i], tpr[i], _ = roc_curve((np.array(all_targets) == i).astype(int), all_probs[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])


    plt.figure()
    for i in range(num_classes):
        plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {i}')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC curves for each class (batch size {batch_size})')
    plt.legend(loc="lower right")
    plt.show()

    wandb.finish()

torch.save(model.state_dict(), 'audio_classification_model.pth')







import torch
import torch.nn as nn
import torch.optim as optim
import torchaudio
import pandas as pd
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import LabelEncoder
from tqdm import tqdm
import os
import wandb

class ESC50Dataset(Dataset):
    def _init_(self, dataframe, base_path, transform=None):
        self.dataframe = dataframe
        self.base_path = base_path
        self.transform = transform

    def _len_(self):
        return len(self.dataframe)

    def _getitem_(self, idx):
        row = self.dataframe.iloc[idx]
        filename = os.path.join(self.base_path, row['filename'])
        waveform, _ = torchaudio.load(filename)
        waveform = waveform[:, :220500]  # Ensure waveform shape is consistent
        label = row['encoded_labels']
        if self.transform:
            waveform = self.transform(waveform)
        return waveform, label

class AudioCNN(nn.Module):
    def _init_(self, num_classes=10):
        super(AudioCNN, self)._init_()
        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(128 * 275, 128)
        self.fc2 = nn.Linear(128, num_classes)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = self.pool(torch.relu(self.conv3(x)))
        x = x.view(-1, 128 * 275)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

def train(model, train_loader, val_loader, optimizer, criterion, epochs=100, early_stop_patience=5):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    best_val_loss = float('inf')
    patience = early_stop_patience
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        correct_predictions = 0
        total_predictions = 0
        loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)
        for i, (inputs, labels) in loop:
            inputs = inputs.to(device)
            labels = labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total_predictions += labels.size(0)
            correct_predictions += (predicted == labels).sum().item()
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            loop.set_description(f"Epoch [{epoch+1}/{epochs}]")
            loop.set_postfix(loss=loss.item())
        train_loss = running_loss / len(train_loader)
        train_accuracy = correct_predictions / total_predictions
        val_loss, val_accuracy = evaluate(model, val_loader, criterion)
        print(f"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}")
        wandb.log({"train_loss": train_loss, "train_accuracy": train_accuracy, "val_loss": val_loss, "val_accuracy": val_accuracy})
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience = early_stop_patience
        else:
            patience -= 1
            if patience == 0:
                print("Early stopping.")
                break

def evaluate(model, data_loader, criterion):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.eval()
    running_loss = 0.0
    correct_predictions = 0
    total_predictions = 0
    with torch.no_grad():
        for inputs, labels in data_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total_predictions += labels.size(0)
            correct_predictions += (predicted == labels).sum().item()
            loss = criterion(outputs, labels)
            running_loss += loss.item()
    loss = running_loss / len(data_loader)
    accuracy = correct_predictions / total_predictions
    return loss, accuracy

# Load data
df = pd.read_csv('/content/drive/MyDrive/Archive/meta/esc50.csv')
df_esc10 = df[df['esc10'] == True]
label_encoder = LabelEncoder()
df_esc10['encoded_labels'] = label_encoder.fit_transform(df_esc10['category'])
base_path = '/content/drive/MyDrive/Archive/audio'

# Split data
train_df, test_df = train_test_split(df_esc10, test_size=0.2, random_state=42)

# Create datasets and data loaders
train_dataset = ESC50Dataset(train_df, base_path)
val_dataset = ESC50Dataset(test_df, base_path)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Initialize model, optimizer, criterion
model = AudioCNN(num_classes=10)
optimizer = optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

# Train the model
wandb.init(project='testi', name='m23cse023')
train(model, train_loader, val_loader, optimizer, criterion)
wandb.finish()

